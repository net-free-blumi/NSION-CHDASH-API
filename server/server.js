import express from 'express';
import cors from 'cors';
import path from 'path';
import { fileURLToPath } from 'url';
import { promises as fs } from 'fs';
import fetch from 'node-fetch';
import { google } from 'googleapis';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const ROOT_PRODUCTS_FILE = path.join(__dirname, '..', 'products.json');
const ROOT_ORDERS_FILE = path.join(__dirname, '..', 'orders.json');
let DATA_DIR = process.env.DATA_DIR || __dirname;
let DATA_PRODUCTS_FILE = path.join(DATA_DIR, 'products.json');
let BACKUPS_DIR = path.join(DATA_DIR, 'backups');
let ORDERS_FILE = path.join(DATA_DIR, 'orders.json');

async function ensureDataLocations() {
    try {
        // Always use local directory for Render compatibility
            DATA_DIR = __dirname;
            DATA_PRODUCTS_FILE = path.join(DATA_DIR, 'products.json');
            BACKUPS_DIR = path.join(DATA_DIR, 'backups');
        ORDERS_FILE = path.join(DATA_DIR, 'orders.json');
        
        // Create directories if they don't exist
            await fs.mkdir(BACKUPS_DIR, { recursive: true });
        // If data file does not exist but root products file exists with data, migrate once
        const dataExists = await fs.access(DATA_PRODUCTS_FILE).then(() => true).catch(() => false);
        if (!dataExists) {
            const rootRaw = await fs.readFile(ROOT_PRODUCTS_FILE, 'utf8').catch(() => '');
            if (rootRaw) {
                await fs.writeFile(DATA_PRODUCTS_FILE, rootRaw, 'utf8');
                console.log('Migrated products.json to persistent data disk');
            } else {
                // initialize empty structure
                await fs.writeFile(DATA_PRODUCTS_FILE, JSON.stringify({ products: {}, categories: {} }, null, 2), 'utf8');
            }
        } else {
            console.log('Products data already exists in persistent storage');
            // Verify the file has content
            const stats = await fs.stat(DATA_PRODUCTS_FILE).catch(() => null);
            if (stats) {
                console.log('Data file size:', stats.size, 'bytes');
            }
        }
        console.log('Data locations ensured. Using:', DATA_PRODUCTS_FILE);
        console.log('‚òÅÔ∏è Cloud storage enabled:', process.env.BACKUP_UPLOAD_TO_CLOUD === 'true' ? 'YES' : 'NO');
    } catch (e) {
        console.error('Failed ensuring data locations:', e);
        // Emergency fallback to local directory
        DATA_DIR = __dirname;
        DATA_PRODUCTS_FILE = path.join(DATA_DIR, 'products.json');
        BACKUPS_DIR = path.join(DATA_DIR, 'backups');
        try {
            await fs.mkdir(BACKUPS_DIR, { recursive: true });
            await fs.writeFile(DATA_PRODUCTS_FILE, JSON.stringify({ products: {}, categories: {} }, null, 2), 'utf8');
            console.log('Emergency fallback: using local directory');
        } catch (fallbackError) {
            console.error('Emergency fallback failed:', fallbackError);
        }
    }
}

function getNowTimestamp() {
    const d = new Date();
    const pad = (n) => String(n).padStart(2, '0');
    return `${d.getFullYear()}${pad(d.getMonth() + 1)}${pad(d.getDate())}-${pad(d.getHours())}${pad(d.getMinutes())}${pad(d.getSeconds())}`;
}

function getFriendlyBackupName() {
    const d = new Date();
    const pad = (n) => String(n).padStart(2, '0');
    // Avoid illegal '/' for Drive filenames
    const datePart = `${pad(d.getDate())}-${pad(d.getMonth() + 1)}-${d.getFullYear()}`;
    const timePart = `${pad(d.getHours())}-${pad(d.getMinutes())}`;
    return `◊í◊ô◊ë◊ï◊ô ◊û◊ï◊¶◊®◊ô◊ù ◊û◊î◊ë◊ê÷∑◊ß ${datePart} - ${timePart}.json`;
}

function getCloudBackupName() {
    const d = new Date();
    const pad = (n) => String(n).padStart(2, '0');
    return `products-${d.getFullYear()}${pad(d.getMonth()+1)}${pad(d.getDate())}-${pad(d.getHours())}${pad(d.getMinutes())}.json`;
}

// ===== Supabase helpers via REST (no external SDK) =====
function getSupabaseEnv() {
    const url = process.env.SUPABASE_URL;
    const key = process.env.SUPABASE_SERVICE_KEY;
    const bucket = process.env.SUPABASE_BUCKET || 'backups';
    if (!url || !key) return null;
    return { url, key, bucket };
}

async function uploadToSupabase(fullPath, destName) {
    if (process.env.BACKUP_UPLOAD_TO_CLOUD !== 'true') return;
    const env = getSupabaseEnv();
    if (!env) return;
    const fileBuffer = await fs.readFile(fullPath);
    const endpoint = `${env.url}/storage/v1/object/${encodeURIComponent(env.bucket)}/${encodeURIComponent(destName)}`;
    const resp = await fetch(endpoint, {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${env.key}`,
            'apikey': env.key,
            'x-upsert': 'true',
            'Content-Type': 'application/json'
        },
        body: fileBuffer
    });
    if (!resp.ok) {
        const t = await resp.text().catch(()=>resp.statusText);
        throw new Error(`supabase upload failed: ${resp.status} ${t}`);
    }
    console.log('‚úÖ Uploaded to Supabase:', destName);
}

async function listSupabaseBackups() {
    const env = getSupabaseEnv();
    if (!env) return [];
    const endpoint = `${env.url}/storage/v1/object/list/${encodeURIComponent(env.bucket)}`;
    const resp = await fetch(endpoint, {
        method: 'POST',
        headers: { 'Authorization': `Bearer ${env.key}`, 'apikey': env.key, 'Content-Type': 'application/json' },
        body: JSON.stringify({ prefix: '', limit: 100, sortBy: { column: 'created_at', order: 'desc' } })
    });
    if (!resp.ok) return [];
    const data = await resp.json().catch(()=>[]);
    const results = [];
    for (const f of (data || []).filter(x => (x.name||'').endsWith('.json'))) {
        let totals = { products: 0, categories: 0 };
        try {
            const raw = await downloadSupabaseBackup(f.name);
            const parsed = JSON.parse(raw || '{}');
            totals.products = parsed.products ? Object.keys(parsed.products).length : 0;
            totals.categories = parsed.categories ? Object.keys(parsed.categories).length : 0;
        } catch {}
        results.push({ type: 'cloud', id: f.name, name: f.name, size: f.metadata?.size || f.size || 0, modifiedTime: f.updated_at || f.created_at || null, totals });
    }
    return results;
}

async function downloadSupabaseBackup(name) {
    const env = getSupabaseEnv();
    if (!env) throw new Error('supabase not configured');
    const endpoint = `${env.url}/storage/v1/object/${encodeURIComponent(env.bucket)}/${encodeURIComponent(name)}`;
    const resp = await fetch(endpoint, { headers: { 'Authorization': `Bearer ${env.key}`, 'apikey': env.key } });
    if (!resp.ok) throw new Error(`download failed: ${resp.status}`);
    return await resp.text();
}

async function deleteSupabaseBackup(name) {
    const env = getSupabaseEnv();
    if (!env) throw new Error('supabase not configured');
    const endpoint = `${env.url}/storage/v1/object/${encodeURIComponent(env.bucket)}`;
    const resp = await fetch(endpoint, {
        method: 'DELETE',
        headers: { 'Authorization': `Bearer ${env.key}`, 'apikey': env.key, 'Content-Type': 'application/json' },
        body: JSON.stringify({ prefixes: [name] })
    });
    if (!resp.ok) throw new Error(`delete failed: ${resp.status}`);
}

async function writeBackupSnapshot(dataObject) {
    try {
        await fs.mkdir(BACKUPS_DIR, { recursive: true });
        const filename = `products-${getNowTimestamp()}.json`;
        const fullPath = path.join(BACKUPS_DIR, filename);
        await fs.writeFile(fullPath, JSON.stringify(dataObject, null, 2), 'utf8');
        console.log('Local backup created at', fullPath);
        // Upload to Supabase if enabled (manual backups only)
        try {
            await uploadToSupabase(fullPath, getCloudBackupName());
        } catch (e) {
            console.warn('Supabase upload failed:', e?.message || e);
        }
        
        console.log('=== BACKUP COMPLETED ===');
    } catch (e) {
        console.warn('Failed to create local backup:', e?.message || e);
    }
}

// Google Drive upload removed per product requirements (listing/restore still supported)

async function getLatestBackupFilePath() {
    try {
        const files = await fs.readdir(BACKUPS_DIR).catch(() => []);
        const productBackups = files.filter(f => /^products-\d{8}-\d{6}\.json$/.test(f));
        if (productBackups.length === 0) return null;
        productBackups.sort();
        return path.join(BACKUPS_DIR, productBackups[productBackups.length - 1]);
    } catch {
        return null;
    }
}

async function getLatestDriveBackup() {
    try {
        const folderId = process.env.GOOGLE_DRIVE_FOLDER_ID;
        if (!folderId) {
            console.log('No Google Drive folder ID configured');
            return null;
        }

        const scopes = ['https://www.googleapis.com/auth/drive.readonly'];
        let auth;
        
        // Try Service Account first
        let svcAccountJson = process.env.GOOGLE_SERVICE_ACCOUNT;
        if (svcAccountJson) {
            try {
                const creds = JSON.parse(svcAccountJson);
                auth = new google.auth.GoogleAuth({ credentials: creds, scopes });
                console.log('‚úÖ Service Account auth created for auto-restore');
            } catch (e) {
                console.error('‚ùå Service Account auth failed for auto-restore:', e?.message);
            }
        }
        
        // Fallback to OAuth
        if (!auth) {
            const clientId = process.env.GOOGLE_OAUTH_CLIENT_ID;
            const clientSecret = process.env.GOOGLE_OAUTH_CLIENT_SECRET;
            const refreshToken = process.env.GOOGLE_OAUTH_REFRESH_TOKEN;
            if (clientId && clientSecret && refreshToken) {
                const oauth2 = new google.auth.OAuth2(clientId, clientSecret);
                oauth2.setCredentials({ refresh_token: refreshToken });
                auth = oauth2;
                console.log('‚úÖ OAuth auth created for auto-restore');
            }
        }
        
        if (!auth) {
            console.log('‚ùå No auth available for Drive auto-restore');
            return null;
        }

        const drive = google.drive({ version: 'v3', auth });
        const resp = await drive.files.list({ 
            q: `'${folderId}' in parents and name contains 'products-' and mimeType = 'application/json'`, 
            fields: 'files(id,name,modifiedTime)', 
            orderBy: 'modifiedTime desc',
            maxResults: 1,
            supportsAllDrives: true,
            includeItemsFromAllDrives: true
        });

        const files = resp.data.files || [];
        if (files.length === 0) {
            console.log('No backup files found in Google Drive');
            return null;
        }

        const latestFile = files[0];
        console.log('Found latest Drive backup:', latestFile.name);
        
        // Download the file
        const fileResp = await drive.files.get({ 
            fileId: latestFile.id, 
            alt: 'media',
            supportsAllDrives: true
        }, { responseType: 'stream' });
        
        const chunks = [];
        await new Promise((resolve, reject) => {
            fileResp.data.on('data', d => chunks.push(d));
            fileResp.data.on('end', resolve);
            fileResp.data.on('error', reject);
        });
        
        const data = Buffer.concat(chunks).toString('utf8');
        return { name: latestFile.name, data: data };
        
    } catch (e) {
        console.error('‚ùå Error getting latest Drive backup:', e?.message || e);
        return null;
    }
}

// Aggregate latest backup across all sources (local, drive, cloud)
async function findLatestBackupAcrossSources() {
    try {
        const candidates = [];

        // Local backups by mtime
        try {
            await fs.mkdir(BACKUPS_DIR, { recursive: true });
            const files = await fs.readdir(BACKUPS_DIR).catch(() => []);
            for (const f of files.filter(x => /^products-\d{8}-\d{6}\.json$/.test(x))) {
                const p = path.join(BACKUPS_DIR, f);
                const st = await fs.stat(p).catch(() => null);
                if (st) {
                    candidates.push({ source: 'local', when: st.mtimeMs, meta: { filename: f, path: p } });
                }
            }
        } catch {}

        // Google Drive backups by modifiedTime
        try {
            const folderId = process.env.GOOGLE_DRIVE_FOLDER_ID;
            if (folderId) {
                const scopes = ['https://www.googleapis.com/auth/drive.readonly'];
                let auth;
                let svcAccountJson = process.env.GOOGLE_SERVICE_ACCOUNT;
                if (svcAccountJson) {
                    try { auth = new google.auth.GoogleAuth({ credentials: JSON.parse(svcAccountJson), scopes }); } catch {}
                }
                if (!auth) {
                    const clientId = process.env.GOOGLE_OAUTH_CLIENT_ID;
                    const clientSecret = process.env.GOOGLE_OAUTH_CLIENT_SECRET;
                    const refreshToken = process.env.GOOGLE_OAUTH_REFRESH_TOKEN;
                    if (clientId && clientSecret && refreshToken) {
                        const oauth2 = new google.auth.OAuth2(clientId, clientSecret);
                        oauth2.setCredentials({ refresh_token: refreshToken });
                        auth = oauth2;
                    }
                }
                if (auth) {
                    const drive = google.drive({ version: 'v3', auth });
                    const resp = await drive.files.list({
                        q: `'${folderId}' in parents and mimeType = 'application/json'`,
                        fields: 'files(id,name,modifiedTime)',
                        orderBy: 'modifiedTime desc',
                        supportsAllDrives: true,
                        includeItemsFromAllDrives: true
                    });
                    const files = resp.data.files || [];
                    for (const f of files) {
                        const when = Date.parse(f.modifiedTime || '') || 0;
                        candidates.push({ source: 'drive', when, meta: { id: f.id, name: f.name } });
                    }
                }
            }
        } catch {}

        // Supabase backups by updated_at/created_at
        try {
            const env = getSupabaseEnv();
            if (env) {
                const endpoint = `${env.url}/storage/v1/object/list/${encodeURIComponent(env.bucket)}`;
                const resp = await fetch(endpoint, {
                    method: 'POST',
                    headers: { 'Authorization': `Bearer ${env.key}`, 'apikey': env.key, 'Content-Type': 'application/json' },
                    body: JSON.stringify({ prefix: '', limit: 100, sortBy: { column: 'updated_at', order: 'desc' } })
                });
                if (resp.ok) {
                    const data = await resp.json().catch(() => []);
                    for (const f of (data || []).filter(x => (x.name||'').endsWith('.json'))) {
                        const when = Date.parse(f.updated_at || f.created_at || '') || 0;
                        candidates.push({ source: 'cloud', when, meta: { name: f.name } });
                    }
                }
            }
        } catch {}

        if (!candidates.length) return null;
        candidates.sort((a, b) => b.when - a.when);
        return candidates[0];
    } catch (e) {
        console.warn('findLatestBackupAcrossSources failed:', e?.message || e);
        return null;
    }
}

async function restoreFromDescriptor(desc) {
    if (!desc) return false;
    try {
        if (desc.source === 'local') {
            const raw = await fs.readFile(desc.meta.path, 'utf8');
            await fs.writeFile(DATA_PRODUCTS_FILE, raw, 'utf8');
            console.log('‚úÖ Restored from local backup:', desc.meta.filename);
            return true;
        }
        if (desc.source === 'drive') {
            const scopes = ['https://www.googleapis.com/auth/drive.readonly'];
            let auth;
            let svcAccountJson = process.env.GOOGLE_SERVICE_ACCOUNT;
            if (svcAccountJson) {
                try { auth = new google.auth.GoogleAuth({ credentials: JSON.parse(svcAccountJson), scopes }); } catch {}
            }
            if (!auth) {
                const clientId = process.env.GOOGLE_OAUTH_CLIENT_ID;
                const clientSecret = process.env.GOOGLE_OAUTH_CLIENT_SECRET;
                const refreshToken = process.env.GOOGLE_OAUTH_REFRESH_TOKEN;
                if (clientId && clientSecret && refreshToken) {
                    const oauth2 = new google.auth.OAuth2(clientId, clientSecret);
                    oauth2.setCredentials({ refresh_token: refreshToken });
                    auth = oauth2;
                }
            }
            if (!auth) throw new Error('drive not configured');
            const drive = google.drive({ version: 'v3', auth });
            const fileResp = await drive.files.get({ fileId: desc.meta.id, alt: 'media', supportsAllDrives: true }, { responseType: 'stream' });
            const chunks = [];
            await new Promise((resolve, reject) => {
                fileResp.data.on('data', d => chunks.push(d));
                fileResp.data.on('end', resolve);
                fileResp.data.on('error', reject);
            });
            const raw = Buffer.concat(chunks).toString('utf8');
            await fs.writeFile(DATA_PRODUCTS_FILE, raw, 'utf8');
            console.log('‚úÖ Restored from Drive backup:', desc.meta.name);
            return true;
        }
        if (desc.source === 'cloud') {
            const raw = await downloadSupabaseBackup(desc.meta.name);
            await fs.writeFile(DATA_PRODUCTS_FILE, raw, 'utf8');
            console.log('‚úÖ Restored from Cloud backup:', desc.meta.name);
            return true;
        }
        return false;
    } catch (e) {
        console.warn('restoreFromDescriptor failed:', e?.message || e);
        return false;
    }
}

async function readJsonSafe(filePath) {
    try {
        const raw = await fs.readFile(filePath, 'utf8');
        return JSON.parse(raw);
    } catch {
        return null;
    }
}

async function createBackupIfChanged() {
    try {
        const current = await readJsonSafe(DATA_PRODUCTS_FILE);
        if (!current) return;
        const latestPath = await getLatestBackupFilePath();
        if (latestPath) {
            const latest = await readJsonSafe(latestPath);
            if (latest && JSON.stringify(latest) === JSON.stringify(current)) {
                console.log('Daily backup skipped: no changes since last snapshot');
                return;
            }
        }
        await writeBackupSnapshot(current);
    } catch (e) {
        console.warn('Daily backup check failed:', e?.message || e);
    }
}

function scheduleDailyConditionalBackup() {
    const days = Math.max(1, parseInt(process.env.BACKUP_INTERVAL_DAYS || '1', 10));
    const intervalMs = days * 24 * 60 * 60 * 1000;
    // run once shortly after start
    setTimeout(() => { createBackupIfChanged(); }, 60 * 1000);
    // schedule interval
    setInterval(() => { createBackupIfChanged(); }, intervalMs);
    console.log(`Scheduled conditional backups every ${days} day(s)`);
}

// Green API configuration
const INSTANCE_ID = '7105260862';
const API_TOKEN = '19d4910c994a45a58d22d1d7cc5d7121fc1575fd6ac143b295';
const BASE_URL = `https://7105.api.greenapi.com/waInstance${INSTANCE_ID}`;

// ◊ß◊ë◊ï◊¶◊ï◊™ ◊ï◊ï◊ê◊ò◊°◊ê◊§
const GROUPS = {
    CONDITORIA: "120363414923943659@g.us", //◊ß◊ï◊†◊ì◊ô◊ò◊ï◊®◊ô◊ô◊î
    FRUITS: "120363414923943659@g.us" //◊§◊ô◊®◊ï◊™
};

// ◊®◊©◊ô◊û◊™ ◊î◊û◊ô◊ô◊ú◊ô◊ù ◊î◊û◊ï◊®◊©◊ô◊ù ◊ú◊©◊ú◊ô◊ó◊™ ◊î◊ï◊ì◊¢◊ï◊™ WhatsApp
const ALLOWED_EMAILS = [
    'BLUMI@GOLDYS.CO.IL',
    'SERVICE@GOLDYS.CO.IL',
    'tzvi@goldys.co.il',
    'ch0548507825@gmail.com',
    'zadok@goldys.co.il'
];

// ◊ë◊ì◊ô◊ß◊î ◊ê◊ù ◊î◊û◊ô◊ô◊ú ◊û◊ï◊®◊©◊î
function isEmailAuthorized(email) {
    return ALLOWED_EMAILS.includes(email.toUpperCase());
}

const app = express();

console.log('üöÄ Server starting with version 2.0.0');
console.log('üìÖ Server start time:', new Date().toISOString());

// Enable CORS (dev-friendly): reflect incoming Origin, allow credentials
app.use((req, res, next) => {
    const origin = req.headers.origin || '*';
    res.header('Access-Control-Allow-Origin', origin);
    res.header('Vary', 'Origin');
    res.header('Access-Control-Allow-Credentials', 'true');
    res.header('Access-Control-Allow-Methods', 'GET,POST,PUT,DELETE,OPTIONS');
    res.header('Access-Control-Allow-Headers', 'Content-Type, Authorization, X-Requested-With, Cache-Control');
    next();
});
app.use(cors({ origin: true, credentials: true }));
app.options('*', cors());

// Parse JSON bodies with increased limit
app.use(express.json({ limit: '50mb' }));

// Serve static files from parent directory
app.use(express.static(path.join(__dirname, '..')));

// Initialize default categories if none exist
async function initializeCategories() {
    try {
        await ensureDataLocations();
        // categories are managed by file; ensure they exist in DATA file
        const filePath = DATA_PRODUCTS_FILE;
        const raw = await fs.readFile(filePath, 'utf8').catch(() => '{"products":{},"categories":{}}');
        const data = JSON.parse(raw || '{}');
        if (data.categories) {
            console.log('Categories already exist in products.json');
            return;
        }
        console.log('Creating initial categories in products.json...');
        const initialCategories = {
                "kitchen": "◊û◊ï◊¶◊®◊ô ◊û◊ò◊ë◊ó",
                "bakery": "◊ß◊ï◊†◊ì◊ô◊ò◊ï◊®◊ô◊ô◊î",
                "fruits": "◊§◊ô◊®◊ï◊™",
                "sushi": "◊°◊ï◊©◊ô",
                "amar": "◊ß◊ï◊†◊ì◊ô◊ò◊ï◊®◊ô◊ô◊î ◊¢◊û◊®",
                "kitchenProducts": "◊û◊ò◊ë◊ó ◊û◊ï◊°◊ò◊§◊î",
                "online": "◊ê◊ï◊†◊ú◊ô◊ô◊ü",
                "warehouse": "◊û◊ó◊°◊ü",
                "sizes": "◊û◊ï◊¶◊®◊ô ◊í◊ì◊ú◊ô◊ù",
                "quantities": "◊û◊ï◊¶◊®◊ô ◊õ◊û◊ï◊™"
            };
        await fs.writeFile(filePath, JSON.stringify({ ...data, categories: initialCategories }, null, 2), 'utf8');
        console.log('Initial categories created in products.json');
    } catch (error) {
        console.error('Error initializing categories:', error);
    }
}

// One-time import from root products.json into MongoDB (if DB is empty)
async function importProductsIfEmpty() {
    try {
        await ensureDataLocations();
        // Products are managed by file; ensure they exist in DATA file
        const filePath = DATA_PRODUCTS_FILE;
        const raw = await fs.readFile(filePath, 'utf8').catch(() => '{"products":{},"categories":{}}');
        const data = JSON.parse(raw || '{}');
        if (data.products) {
            console.log('Products already exist in products.json');
            return;
        }
        console.log('Creating initial products in products.json...');
        const initialProducts = {
            "kitchen": {
                "code": "KITCHEN_001",
                "name": "◊û◊ï◊¶◊®◊ô ◊û◊ò◊ë◊ó",
                "price": 100,
                "quantity": 10,
                "category": "kitchen",
                "description": "◊û◊ï◊¶◊®◊ô ◊û◊ò◊ë◊ó ◊õ◊ú◊ú◊ô"
            },
            "bakery": {
                "code": "BAKERY_001",
                "name": "◊ß◊ï◊†◊ì◊ô◊ò◊ï◊®◊ô◊ô◊î",
                "price": 50,
                "quantity": 20,
                "category": "bakery",
                "description": "◊ß◊ï◊†◊ì◊ô◊ò◊ï◊®◊ô◊ô◊î ◊õ◊ú◊ú◊ô◊™"
            },
            "fruits": {
                "code": "FRUITS_001",
                "name": "◊§◊ô◊®◊ï◊™",
                "price": 20,
                "quantity": 50,
                "category": "fruits",
                "description": "◊§◊ô◊®◊ï◊™ ◊õ◊ú◊ú◊ô◊ô◊ù"
            },
            "sushi": {
                "code": "SUSHI_001",
                "name": "◊°◊ï◊©◊ô",
                "price": 150,
                "quantity": 15,
                "category": "sushi",
                "description": "◊°◊ï◊©◊ô ◊õ◊ú◊ú◊ô"
            },
            "amar": {
                "code": "AMAR_001",
                "name": "◊ß◊ï◊†◊ì◊ô◊ò◊ï◊®◊ô◊ô◊î ◊¢◊û◊®",
                "price": 80,
                "quantity": 10,
                "category": "amar",
                "description": "◊ß◊ï◊†◊ì◊ô◊ò◊ï◊®◊ô◊ô◊î ◊¢◊û◊® ◊õ◊ú◊ú◊ô◊™"
            },
            "kitchenProducts": {
                "code": "KITCHEN_PRODUCTS_001",
                "name": "◊û◊ò◊ë◊ó ◊û◊ï◊°◊ò◊§◊î",
                "price": 200,
                "quantity": 5,
                "category": "kitchenProducts",
                "description": "◊û◊ò◊ë◊ó ◊û◊ï◊°◊ò◊§◊î ◊õ◊ú◊ú◊ô◊™"
            },
            "online": {
                "code": "ONLINE_001",
                "name": "◊ê◊ï◊†◊ú◊ô◊ô◊ü",
                "price": 500,
                "quantity": 1,
                "category": "online",
                "description": "◊ê◊ï◊†◊ú◊ô◊ô◊ü ◊õ◊ú◊ú◊ô"
            },
            "warehouse": {
                "code": "WAREHOUSE_001",
                "name": "◊û◊ó◊°◊ü",
                "price": 1000,
                "quantity": 1,
                "category": "warehouse",
                "description": "◊û◊ó◊°◊ü ◊õ◊ú◊ú◊ô"
            },
            "sizes": {
                "code": "SIZES_001",
                "name": "◊û◊ï◊¶◊®◊ô ◊í◊ì◊ú◊ô◊ù",
                "price": 50,
                "quantity": 100,
                "category": "sizes",
                "description": "◊û◊ï◊¶◊®◊ô ◊í◊ì◊ú◊ô◊ù ◊õ◊ú◊ú◊ô◊ô◊ù"
            },
            "quantities": {
                "code": "QUANTITIES_001",
                "name": "◊û◊ï◊¶◊®◊ô ◊õ◊û◊ï◊™",
                "price": 10,
                "quantity": 200,
                "category": "quantities",
                "description": "◊û◊ï◊¶◊®◊ô ◊õ◊û◊ï◊™ ◊õ◊ú◊ú◊ô◊ô◊ù"
            }
        };
        await fs.writeFile(filePath, JSON.stringify({ ...data, products: initialProducts }, null, 2), 'utf8');
        console.log('Initial products created in products.json');
    } catch (error) {
        console.error('Error importing products into MongoDB:', error.message);
    }
}

// Error handling middleware
app.use((err, req, res, next) => {
    console.error('Unhandled error:', err);
    res.status(500).json({
        error: '◊©◊í◊ô◊ê◊î ◊ë◊©◊®◊™',
        details: process.env.NODE_ENV === 'development' ? err.message : undefined
    });
});

// API Stats endpoint for health check
app.get('/api/stats', async (req, res) => {
    try {
        const filePath = DATA_PRODUCTS_FILE;
        const raw = await fs.readFile(filePath, 'utf8').catch(() => '{"products":{},"categories":{}}');
        const data = JSON.parse(raw || '{}');
        const stats = {
            total: data.products ? Object.keys(data.products).length : 0,
            categories: data.categories ? Object.keys(data.categories).length : 0,
            status: 'ok',
            server: 'running(file+data)'
        };
        console.log('Stats request successful:', stats);
        res.json(stats);
    } catch (error) {
        console.error('Error getting stats:', error);
        res.status(500).json({ error: '◊©◊í◊ô◊ê◊î ◊ë◊ß◊ë◊ú◊™ ◊°◊ò◊ò◊ô◊°◊ò◊ô◊ß◊ï◊™' });
    }
});

// Save products endpoint
app.post('/api/products/save', async (req, res) => {
    try {
        console.log('Save products request received');
        const { products, categories, timestamp, replace } = req.body;
        
        if (!products) {
            return res.status(400).json({ error: 'products missing' });
        }

        // Ensure data directory exists before any file operations
        await ensureDataLocations();
        
        const filePath = DATA_PRODUCTS_FILE;
        const raw = await fs.readFile(filePath, 'utf8').catch(() => '{"products":{},"categories":{}}');
        const data = JSON.parse(raw || '{}');
        const merged = { products: data.products || {}, categories: data.categories || {} };

        if (replace) {
            // ◊î◊ó◊ú◊§◊î ◊û◊ú◊ê◊î ◊©◊ú ◊î◊û◊ï◊¶◊®◊ô◊ù
            merged.products = products;
        } else {
            // ◊õ◊™◊ô◊ë◊™ ◊ì◊ú◊™◊ê: ◊¢◊ì◊õ◊ï◊ü ◊®◊ß ◊û◊î ◊©◊î◊í◊ô◊¢ ◊ë◊ë◊ß◊©◊î
            for (const [code, p] of Object.entries(products)) {
                merged.products[code] = { ...(merged.products[code] || {}), ...p };
                
                // ◊û◊ó◊ô◊ß◊™ ◊©◊ì◊ï◊™ ◊©◊û◊ï◊í◊ì◊®◊ô◊ù ◊õ-null (◊ú◊û◊ó◊ô◊ß◊î)
                for (const [key, value] of Object.entries(p)) {
                    if (value === null) {
                        delete merged.products[code][key];
                    }
                }
            }
        }
        if (categories) {
            merged.categories = { ...merged.categories, ...categories };
        }
        await fs.writeFile(filePath, JSON.stringify(merged, null, 2), 'utf8');
        
        // ◊©◊û◊ô◊®◊î ◊ê◊ï◊ò◊ï◊û◊ò◊ô◊™ ◊ú◊¢◊†◊ü ◊ê◊ó◊®◊ô ◊õ◊ú ◊©◊û◊ô◊®◊™ ◊û◊ï◊¶◊®◊ô◊ù
        try {
            await uploadProductsToCloud(merged);
            console.log('‚úÖ Products automatically saved to cloud');
        } catch (cloudError) {
            console.warn('‚ö†Ô∏è Failed to save products to cloud:', cloudError.message);
            // ◊ú◊ê ◊†◊õ◊©◊ú ◊ê◊™ ◊î◊ë◊ß◊©◊î ◊ê◊ù ◊î◊©◊û◊ô◊®◊î ◊ú◊¢◊†◊ü ◊†◊õ◊©◊ú◊™
        }
        
        // Auto backups on save are disabled per product requirements

        res.json({
            success: true,
            message: '◊î◊û◊ï◊¶◊®◊ô◊ù ◊†◊©◊û◊®◊ï ◊ë◊î◊¶◊ú◊ó◊î',
            timestamp: timestamp || new Date().toISOString()
        });
    } catch (error) {
        console.error('Error saving products:', error);
        res.status(500).json({ error: '◊©◊í◊ô◊ê◊î ◊ë◊©◊û◊ô◊®◊™ ◊î◊û◊ï◊¶◊®◊ô◊ù' });
    }
});

// Get all products
app.get('/api/products', async (req, res) => {
    try {
        res.set('Cache-Control', 'no-store');
        // Ensure data directory exists before any file operations
        await ensureDataLocations();
        
        const filePath = DATA_PRODUCTS_FILE;
        const raw = await fs.readFile(filePath, 'utf8').catch(() => '{"products":{},"categories":{}}');
        const data = JSON.parse(raw || '{}');
        // Auto-restore if products are empty and auto-restore is enabled
        const autoRestore = process.env.AUTO_RESTORE_ON_EMPTY === 'true';
        const productsCount = data.products ? Object.keys(data.products).length : 0;
        
        if (productsCount === 0) {
            console.log('üîÑ Products count is 0, attempting auto-restore from cloud...');
            try {
                const list = await listSupabaseBackups();
                if (list && list.length) {
                    const latest = list[0];
                    const rawCloud = await downloadSupabaseBackup(latest.name);
                    await fs.writeFile(filePath, rawCloud, 'utf8');
                    const parsed = JSON.parse(rawCloud || '{}');
                    console.log('‚úÖ Products restored from cloud backup:', latest.name);
                    return res.json({ products: parsed.products || {}, categories: parsed.categories || {}, restoredFrom: 'cloud' });
                }
            } catch (e) {
                console.warn('Cloud auto-restore failed:', e?.message || e);
            }
            console.log('‚ùå No cloud backups found for auto-restore');
        }
        res.json({ products: data.products || {}, categories: data.categories || {} });
    } catch (error) {
        console.error('Error reading products:', error);
        res.status(500).json({ error: '◊©◊í◊ô◊ê◊î ◊ë◊ß◊®◊ô◊ê◊™ ◊î◊û◊ï◊¶◊®◊ô◊ù' });
    }
});

// Delete a single product by code
app.delete('/api/products/:code', async (req, res) => {
    try {
        const { code } = req.params;
        if (!code) return res.status(400).json({ error: 'missing code' });

        // Ensure data directory exists before any file operations
        await ensureDataLocations();
        
        const filePath = DATA_PRODUCTS_FILE;
        const raw = await fs.readFile(filePath, 'utf8').catch(() => '{"products":{},"categories":{}}');
        const data = JSON.parse(raw || '{}');
        if (data.products && data.products[code]) {
            delete data.products[code];
            await fs.writeFile(filePath, JSON.stringify(data, null, 2), 'utf8');
        }

        res.json({ success: true, message: `Product ${code} deleted` });
    } catch (error) {
        console.error('Error deleting product:', error);
        res.status(500).json({ error: '◊©◊í◊ô◊ê◊î ◊ë◊û◊ó◊ô◊ß◊™ ◊î◊û◊ï◊¶◊®' });
    }
});

// Health check endpoint
app.get('/health', (req, res) => {
    res.json({ status: 'ok', timestamp: new Date().toISOString() });
});

// Debug endpoint to check if server is updated
app.get('/api/debug', (req, res) => {
    res.json({ 
        message: 'Server is updated with latest code',
        timestamp: new Date().toISOString(),
        version: '2.0.0'
    });
});

// Environment variables debug endpoint
app.get('/api/env-debug', (req, res) => {
    res.json({
        BACKUP_UPLOAD_TO_DRIVE: process.env.BACKUP_UPLOAD_TO_DRIVE,
        BACKUP_MODE: process.env.BACKUP_MODE,
        GOOGLE_DRIVE_FOLDER_ID: process.env.GOOGLE_DRIVE_FOLDER_ID,
        GOOGLE_SERVICE_ACCOUNT: process.env.GOOGLE_SERVICE_ACCOUNT ? 'EXISTS' : 'MISSING',
        GOOGLE_SERVICE_ACCOUNT_LENGTH: process.env.GOOGLE_SERVICE_ACCOUNT ? process.env.GOOGLE_SERVICE_ACCOUNT.length : 0,
        AUTO_RESTORE_ON_EMPTY: process.env.AUTO_RESTORE_ON_EMPTY,
        BACKUP_ENABLED: process.env.BACKUP_ENABLED
    });
});

// Test Google Drive connection
app.get('/api/test-drive', async (req, res) => {
    try {
    // Google Drive connection test (kept minimal logging)
        
        const folderId = process.env.GOOGLE_DRIVE_FOLDER_ID;
        if (!folderId) {
            return res.json({ error: 'No Google Drive folder ID configured' });
        }
        
        const scopes = ['https://www.googleapis.com/auth/drive.readonly'];
        let auth;
        
        // Try Service Account
        let svcAccountJson = process.env.GOOGLE_SERVICE_ACCOUNT;
        if (svcAccountJson) {
            try {
                const creds = JSON.parse(svcAccountJson);
                auth = new google.auth.GoogleAuth({ credentials: creds, scopes });
                console.log('‚úÖ Service Account auth created');
            } catch (e) {
                console.error('‚ùå Service Account auth failed:', e?.message);
            }
        }
        
        if (!auth) {
            return res.json({ error: 'No Google Drive authentication configured' });
        }
        
        const drive = google.drive({ version: 'v3', auth });
        const result = await drive.files.list({ 
            q: `'${folderId}' in parents`, 
            maxResults: 1,
            supportsAllDrives: true,
            includeItemsFromAllDrives: true
        });
        
        res.json({ 
            success: true, 
            message: 'Google Drive connection working',
            folderId: folderId,
            filesFound: result.data.files?.length || 0
        });
    } catch (e) {
        console.error('Google Drive test failed:', e?.message);
        res.status(500).json({ error: 'Google Drive test failed', details: e?.message });
    }
});

// Manual backup endpoint (forces snapshot + optional Drive upload)
app.post('/api/backup-now', async (req, res) => {
    try {
        console.log('=== MANUAL BACKUP REQUEST ===');
        
        const raw = await fs.readFile(DATA_PRODUCTS_FILE, 'utf8').catch(() => null);
        if (!raw) {
            console.error('‚ùå No data file found for backup');
            return res.status(404).json({ error: 'no data file' });
        }
        console.log('‚úÖ Data file found, size:', raw.length);
        
        const data = JSON.parse(raw || '{}');
        console.log('Data parsed, products:', Object.keys(data.products || {}).length);
        
        console.log('üöÄ Starting backup snapshot...');
        await writeBackupSnapshot(data);
        console.log('‚úÖ Backup snapshot completed');
        
        const totals = {
            products: data.products ? Object.keys(data.products).length : 0,
            categories: data.categories ? Object.keys(data.categories).length : 0
        };
        console.log('Backup totals:', totals);
        console.log('=== MANUAL BACKUP COMPLETED ===');
        res.json({ success: true, message: 'Backup created', totals });
    } catch (e) {
        console.error('‚ùå Manual backup failed:', e);
        console.error('Error details:', e);
        res.status(500).json({ error: 'backup failed', details: e?.message });
    }
});

// Backup status endpoint
app.get('/api/backup-status', async (req, res) => {
    try {
        const latest = await getLatestBackupFilePath();
        const exists = !!latest;
        res.json({
            exists,
            latestPath: latest || null,
            folderId: process.env.GOOGLE_DRIVE_FOLDER_ID || '1lzqjieLaOaGMgrUjzRvYzMIZndfg1DGe'
        });
    } catch (e) {
        res.status(500).json({ error: 'status failed', details: e?.message });
    }
});

// List local backups with metadata and counts
app.get('/api/backups', async (req, res) => {
    try {
        await ensureDataLocations();
        const files = await fs.readdir(BACKUPS_DIR).catch(() => []);
        const list = [];
        for (const f of files.filter(x => /^products-\d{8}-\d{6}\.json$/.test(x)).sort().reverse()) {
            const p = path.join(BACKUPS_DIR, f);
            const st = await fs.stat(p).catch(() => null);
            let totals = { products: 0, categories: 0 };
            try {
                const raw = await fs.readFile(p, 'utf8');
                const data = JSON.parse(raw || '{}');
                totals.products = data.products ? Object.keys(data.products).length : 0;
                totals.categories = data.categories ? Object.keys(data.categories).length : 0;
            } catch {}
            list.push({
                type: 'local',
                filename: f,
                path: p,
                size: st?.size || 0,
                mtime: st?.mtime || null,
                totals
            });
        }
        res.json({ success: true, backups: list });
    } catch (e) {
        res.status(500).json({ error: 'list failed', details: e?.message });
    }
});

// List Google Drive backups (if configured)
app.get('/api/drive-backups', async (req, res) => {
    try {
        const folderId = process.env.GOOGLE_DRIVE_FOLDER_ID;
        if (!folderId) return res.json({ success: true, backups: [] });

        const scopes = ['https://www.googleapis.com/auth/drive.readonly'];
        let auth;
        let svcAccountJson = process.env.GOOGLE_SERVICE_ACCOUNT;
        if (svcAccountJson) {
            try { auth = new google.auth.GoogleAuth({ credentials: JSON.parse(svcAccountJson), scopes }); } catch {}
        }
        if (!auth) {
            const clientId = process.env.GOOGLE_OAUTH_CLIENT_ID;
            const clientSecret = process.env.GOOGLE_OAUTH_CLIENT_SECRET;
            const refreshToken = process.env.GOOGLE_OAUTH_REFRESH_TOKEN;
            if (clientId && clientSecret && refreshToken) {
                const oauth2 = new google.auth.OAuth2(clientId, clientSecret);
                oauth2.setCredentials({ refresh_token: refreshToken });
                auth = oauth2;
            }
        }
        if (!auth) return res.json({ success: true, backups: [] });

        const drive = google.drive({ version: 'v3', auth });
        const resp = await drive.files.list({ 
            q: `'${folderId}' in parents and mimeType = 'application/json'`, 
            fields: 'files(id,name,modifiedTime,size)', 
            orderBy: 'modifiedTime desc',
            supportsAllDrives: true,
            includeItemsFromAllDrives: true
        });

        const files = resp.data.files || [];
        const backups = [];
        for (const f of files) {
            let totals = { products: 0, categories: 0 };
            try {
                const fileResp = await drive.files.get({ fileId: f.id, alt: 'media', supportsAllDrives: true }, { responseType: 'stream' });
                const chunks = [];
                await new Promise((resolve, reject) => {
                    fileResp.data.on('data', d => chunks.push(d));
                    fileResp.data.on('end', resolve);
                    fileResp.data.on('error', reject);
                });
                const raw = Buffer.concat(chunks).toString('utf8');
                const data = JSON.parse(raw || '{}');
                totals.products = data.products ? Object.keys(data.products).length : 0;
                totals.categories = data.categories ? Object.keys(data.categories).length : 0;
            } catch {}
            backups.push({ type: 'drive', id: f.id, name: f.name, modifiedTime: f.modifiedTime, size: parseInt(f.size || '0', 10), totals });
        }
        res.json({ success: true, backups });
    } catch (e) {
        res.status(500).json({ error: 'drive list failed', details: e?.message });
    }
});

// List Supabase cloud backups
app.get('/api/cloud-backups', async (req, res) => {
    try {
        const list = await listSupabaseBackups();
        res.json({ success: true, backups: list });
    } catch (e) {
        res.status(500).json({ error: 'cloud list failed', details: e?.message });
    }
});

// Restore from chosen backup (local or drive)
app.post('/api/restore', async (req, res) => {
    try {
        const { source, id, filename } = req.body || {};
        await ensureDataLocations();
        let raw;
        if (source === 'local' && filename) {
            const p = path.join(BACKUPS_DIR, filename);
            raw = await fs.readFile(p, 'utf8');
        } else if (source === 'drive' && id) {
            const scopes = ['https://www.googleapis.com/auth/drive.readonly'];
            let auth;
            let svcAccountJson = process.env.GOOGLE_SERVICE_ACCOUNT;
            if (svcAccountJson) {
                try { auth = new google.auth.GoogleAuth({ credentials: JSON.parse(svcAccountJson), scopes }); } catch {}
            }
            if (!auth) {
                const clientId = process.env.GOOGLE_OAUTH_CLIENT_ID;
                const clientSecret = process.env.GOOGLE_OAUTH_CLIENT_SECRET;
                const refreshToken = process.env.GOOGLE_OAUTH_REFRESH_TOKEN;
                if (clientId && clientSecret && refreshToken) {
                    const oauth2 = new google.auth.OAuth2(clientId, clientSecret);
                    oauth2.setCredentials({ refresh_token: refreshToken });
                    auth = oauth2;
                }
            }
            if (!auth) return res.status(400).json({ error: 'drive not configured' });
            const drive = google.drive({ version: 'v3', auth });
            const fileResp = await drive.files.get({ 
                fileId: id, 
                alt: 'media',
                supportsAllDrives: true
            }, { responseType: 'stream' });
            const chunks = [];
            await new Promise((resolve, reject) => {
                fileResp.data.on('data', d => chunks.push(d));
                fileResp.data.on('end', resolve);
                fileResp.data.on('error', reject);
            });
            raw = Buffer.concat(chunks).toString('utf8');
        } else if (source === 'cloud' && (id || filename)) {
            const name = filename || id;
            raw = await downloadSupabaseBackup(name);
        } else {
            return res.status(400).json({ error: 'invalid source' });
        }

        await fs.writeFile(DATA_PRODUCTS_FILE, raw, 'utf8');
        const parsed = JSON.parse(raw || '{}');
        res.json({ success: true, totals: { products: Object.keys(parsed.products || {}).length, categories: Object.keys(parsed.categories || {}).length } });
    } catch (e) {
        res.status(500).json({ error: 'restore failed', details: e?.message });
    }
});

// Restore-latest (local) removed from UI use; manual restore via modal remains

// Delete backup endpoint
app.post('/api/delete-backup', async (req, res) => {
    try {
        // Minimal logging for delete backup
        
        // Simple test response first
        if (req.body.test === 'true') {
            return res.json({ success: true, message: 'Delete endpoint working', version: '2.0.0' });
        }
        
        const { source, id, filename } = req.body;
        console.log('Delete parameters:', { source, id, filename });
        
        if (source === 'local' && filename) {
            console.log('üóëÔ∏è Deleting local backup:', filename);
            const backupPath = path.join(BACKUPS_DIR, filename);
            console.log('Backup path:', backupPath);
            await fs.unlink(backupPath);
            console.log('‚úÖ Local backup deleted successfully');
            res.json({ success: true, message: 'Local backup deleted' });
        } else if (source === 'drive' && id) {
            console.log('Deleting Drive backup');
            const scopes = ['https://www.googleapis.com/auth/drive.file'];
            let auth;
            
            // Try Service Account first
            let svcAccountJson = process.env.GOOGLE_SERVICE_ACCOUNT;
            console.log('Service Account for delete:', !!svcAccountJson);
            if (svcAccountJson) {
                try { 
                    auth = new google.auth.GoogleAuth({ credentials: JSON.parse(svcAccountJson), scopes }); 
                    console.log('‚úÖ Service Account auth created for delete');
                } catch (e) {
                    console.error('‚ùå Service Account auth failed for delete:', e?.message);
                }
            }
            
            // Fallback to OAuth
            if (!auth) {
                console.log('Trying OAuth for delete...');
                const clientId = process.env.GOOGLE_OAUTH_CLIENT_ID;
                const clientSecret = process.env.GOOGLE_OAUTH_CLIENT_SECRET;
                const refreshToken = process.env.GOOGLE_OAUTH_REFRESH_TOKEN;
                if (clientId && clientSecret && refreshToken) {
                    const oauth2 = new google.auth.OAuth2(clientId, clientSecret);
                    oauth2.setCredentials({ refresh_token: refreshToken });
                    auth = oauth2;
                    console.log('‚úÖ OAuth auth created for delete');
                } else {
                    console.log('‚ùå No OAuth credentials for delete');
                }
            }
            
            if (!auth) {
                console.error('‚ùå No auth available for Drive delete');
                return res.status(400).json({ error: 'drive not configured' });
            }
            
            const drive = google.drive({ version: 'v3', auth });
            
            await drive.files.delete({ 
                fileId: id,
                supportsAllDrives: true
            });
            
            res.json({ success: true, message: 'Drive backup deleted' });
        } else if (source === 'cloud' && (id || filename)) {
            const name = filename || id;
            await deleteSupabaseBackup(name);
            res.json({ success: true, message: 'Cloud backup deleted' });
        } else {
            console.error('‚ùå Invalid delete parameters');
            res.status(400).json({ error: 'invalid parameters' });
        }
        console.log('=== DELETE BACKUP COMPLETED ===');
    } catch (e) {
        console.error('‚ùå Delete backup failed:', e?.message || e);
        console.error('Error details:', e);
        res.status(500).json({ error: 'delete failed', details: e?.message });
    }
});

// ===== ORDERS MANAGEMENT SYSTEM =====

// Orders data structure
let ORDERS_BACKUPS_DIR = null; // Will be set in ensureDataLocations

// Initialize orders data
async function ensureOrdersData() {
    try {
        await ensureDataLocations(); // Make sure data locations are set
        
        // Set ORDERS_BACKUPS_DIR after ensureDataLocations
        ORDERS_BACKUPS_DIR = path.join(DATA_DIR, 'orders-backups');
        
        await fs.mkdir(ORDERS_BACKUPS_DIR, { recursive: true });
        const ordersExists = await fs.access(ORDERS_FILE).then(() => true).catch(() => false);
        if (!ordersExists) {
            await fs.writeFile(ORDERS_FILE, JSON.stringify({ orders: {}, currentOrder: null }, null, 2), 'utf8');
            console.log('Orders data initialized');
        }
    } catch (e) {
        console.error('Failed to initialize orders data:', e);
    }
}

// Upload products to cloud (Supabase)
async function uploadProductsToCloud(productsData) {
    if (process.env.BACKUP_UPLOAD_TO_CLOUD !== 'true') return;
    const env = getSupabaseEnv();
    if (!env) return;
    
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `products-${timestamp}.json`;
    
    try {
        const endpoint = `${env.url}/storage/v1/object/${encodeURIComponent(env.bucket)}/${encodeURIComponent(filename)}`;
        const response = await fetch(endpoint, {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${env.key}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify(productsData)
        });
        
        if (!response.ok) {
            throw new Error(`Supabase upload failed: ${response.status} ${response.statusText}`);
        }
        
        console.log(`‚úÖ Products uploaded to cloud: ${filename}`);
    } catch (error) {
        console.error('‚ùå Failed to upload products to cloud:', error);
        throw error;
    }
}

// Save order to cloud (Supabase)
async function saveOrderToCloud(orderData) {
    if (process.env.BACKUP_UPLOAD_TO_CLOUD !== 'true') return;
    const env = getSupabaseEnv();
    if (!env) return;
    
    const orderId = orderData.id || `order-${Date.now()}`;
    const filename = `orders/${orderId}.json`;
    
    const fileBuffer = Buffer.from(JSON.stringify(orderData, null, 2), 'utf8');
    const endpoint = `${env.url}/storage/v1/object/${encodeURIComponent(env.bucket)}/${encodeURIComponent(filename)}`;
    
    const resp = await fetch(endpoint, {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${env.key}`,
            'apikey': env.key,
            'x-upsert': 'true',
            'Content-Type': 'application/json'
        },
        body: fileBuffer
    });
    
    if (!resp.ok) {
        const t = await resp.text().catch(() => resp.statusText);
        throw new Error(`supabase upload failed: ${resp.status} ${t}`);
    }
    
    console.log('‚úÖ Order saved to cloud:', orderId);
}

// Delete order from cloud
app.delete('/api/orders/delete/:orderId', async (req, res) => {
    try {
        const { orderId } = req.params;
        const env = getSupabaseEnv();
        
        if (!env) {
            return res.status(500).json({ error: 'Cloud storage not configured' });
        }
        
        // Delete from Supabase - ◊™◊ô◊ß◊ï◊ü URL
        const fileName = `${orderId}.json`;
        
        // ◊†◊°◊î ◊¢◊ù ◊î◊ß◊ï◊ë◊• ◊¢◊ù/◊ë◊ú◊ô "orders/" prefix
        const pathsToTry = [
            `orders/${fileName}`,
            fileName
        ];
        
        let deleted = false;
        for (const filePath of pathsToTry) {
            try {
                const deleteUrl = `${env.url}/storage/v1/object/${encodeURIComponent(env.bucket)}/${encodeURIComponent(filePath)}`;
                console.log(`üîó ◊û◊†◊°◊î ◊ú◊û◊ó◊ï◊ß: ${deleteUrl}`);
                
                const deleteResp = await fetch(deleteUrl, {
                    method: 'DELETE',
                    headers: {
                        'Authorization': `Bearer ${env.key}`,
                        'apikey': env.key
                    }
                });
                
                console.log(`üì• ◊™◊í◊ï◊ë◊™ ◊û◊ó◊ô◊ß◊î: ${deleteResp.status}`);
                
                if (deleteResp.ok || deleteResp.status === 404) {
                    console.log(`‚úÖ Order deleted from cloud: ${fileName}`);
                    deleted = true;
                    break;
                }
            } catch (e) {
                console.warn(`‚ö†Ô∏è ◊†◊õ◊©◊ú ◊ë◊†◊°◊ô◊ï◊ü ◊ú◊û◊ó◊ï◊ß ◊ê◊™ ${filePath}:`, e.message);
                continue;
            }
        }
        
        if (deleted) {
            res.json({ success: true, message: 'Order deleted successfully' });
        } else {
            console.error(`‚ùå Failed to delete order from cloud: ${fileName}`);
            // ◊†◊©◊ú◊ó success ◊ë◊õ◊ú ◊ñ◊ê◊™ ◊õ◊ô ◊ñ◊î ◊ú◊ê ◊û◊©◊§◊ô◊¢ ◊¢◊ú ◊î◊û◊©◊™◊û◊©
            res.json({ success: true, message: 'Order deletion attempted (may not have existed)' });
        }
    } catch (error) {
        console.error('Error deleting order from cloud:', error);
        // ◊†◊©◊ú◊ó success ◊õ◊ì◊ô ◊ú◊ê ◊ú◊©◊ë◊ï◊® ◊ê◊™ ◊î◊ó◊ï◊ï◊ô◊î
        res.json({ success: true, message: 'Order deletion attempted' });
    }
});

        // Get orders from cloud
        async function getOrdersFromCloud() {
            const env = getSupabaseEnv();
            if (!env) return { orders: [] };
            
            const endpoint = `${env.url}/storage/v1/object/list/${encodeURIComponent(env.bucket)}`;
            const resp = await fetch(endpoint, {
                method: 'POST',
                headers: { 'Authorization': `Bearer ${env.key}`, 'apikey': env.key, 'Content-Type': 'application/json' },
                body: JSON.stringify({ prefix: 'orders/', limit: 100, sortBy: { column: 'created_at', order: 'desc' } })
            });
            
            if (!resp.ok) {
                console.warn('Failed to list cloud orders:', resp.status, resp.statusText);
                return { orders: [] };
            }
            const data = await resp.json().catch(() => []);
            console.log('üìã Cloud orders list response:', data?.length || 0, 'files found');
            
            const results = [];
            for (const f of (data || []).filter(x => (x.name || '').endsWith('.json'))) {
                try {
                    console.log('üîç Processing file:', f.name);
                    // ◊î◊õ◊†◊™ ◊©◊ù ◊î◊ß◊ï◊ë◊•
                    const fileName = f.name.replace('orders/', '');
                    
                    // ◊†◊°◊ô◊ï◊ü ◊¢◊ù ◊©◊†◊ô ◊†◊™◊ô◊ë◊ô◊ù ◊ê◊§◊©◊®◊ô◊ô◊ù
                    const endpointsToTry = [
                        `${env.url}/storage/v1/object/public/${encodeURIComponent(env.bucket)}/orders/${fileName}`,
                        `${env.url}/storage/v1/object/public/${encodeURIComponent(env.bucket)}/${f.name}`,
                        `${env.url}/storage/v1/object/${encodeURIComponent(env.bucket)}/orders/${fileName}`
                    ];
                    
                    let orderResp = null;
                    for (const orderEndpoint of endpointsToTry) {
                        try {
                            console.log('üîó Trying endpoint:', orderEndpoint);
                            orderResp = await fetch(orderEndpoint, {
                                headers: {
                                    'Authorization': `Bearer ${env.key}`,
                                    'apikey': env.key
                                }
                            });
                            console.log('üì• Order response status:', orderResp.status);
                            if (orderResp.ok) {
                                break;
                            }
                        } catch (e) {
                            console.warn('‚ö†Ô∏è Failed to fetch from:', orderEndpoint, e.message);
                            continue;
                        }
                    }
                    
                    if (orderResp && orderResp.ok) {
                        const orderData = await orderResp.json();
                        console.log('üìã Order data loaded successfully');
                        results.push({
                            id: fileName.replace('.json', ''),
                            orderNumber: orderData.orderNumber || fileName.replace('.json', ''),
                            date: orderData.orderDate || orderData.createdDate || new Date(orderData.createdAt).toLocaleDateString('he-IL'),
                            time: orderData.orderTime || orderData.createdTime || new Date(orderData.createdAt).toLocaleTimeString('he-IL'),
                            total: orderData.total || 0,
                            items: orderData.items || {},
                            status: orderData.status || 'completed',
                            data: orderData
                        });
                        console.log('‚úÖ Loaded order from cloud:', fileName);
                    } else {
                        console.warn('‚ùå Failed to load order file:', fileName, 'status:', orderResp?.status);
                    }
                } catch (e) {
                    console.warn('‚ùå Failed to load order:', f.name, e);
                }
            }
            
            console.log('üìã Total cloud orders loaded:', results.length);
            return { orders: results };
        }

// Download specific order from cloud
async function downloadOrderFromCloud(orderId) {
    const env = getSupabaseEnv();
    if (!env) throw new Error('supabase not configured');
    
    const filename = `orders/${orderId}.json`;
    const endpoint = `${env.url}/storage/v1/object/${encodeURIComponent(env.bucket)}/${encodeURIComponent(filename)}`;
    const resp = await fetch(endpoint, { headers: { 'Authorization': `Bearer ${env.key}`, 'apikey': env.key } });
    
    if (!resp.ok) throw new Error(`download failed: ${resp.status}`);
    return await resp.json();
}

// Create or update order
app.post('/api/orders/create', async (req, res) => {
    try {
        await ensureOrdersData();
        const { customerName, items, total, notes, orderNumber, orderDate, orderTime } = req.body;
        
        let orderId = `order-${Date.now()}`;
        let existingOrderId = null;
        
        // ◊ë◊ì◊ô◊ß◊î ◊ê◊ù ◊ô◊© ◊î◊ñ◊û◊†◊î ◊ß◊ô◊ô◊û◊™ ◊¢◊ù ◊ê◊ï◊™◊ï ◊û◊°◊§◊® ◊î◊ñ◊û◊†◊î
        if (orderNumber) {
            try {
                const env = getSupabaseEnv();
                if (env) {
                    const listResp = await fetch(`${env.url}/storage/v1/object/list/${encodeURIComponent(env.bucket)}`, {
                        method: 'POST',
                        headers: { 'Authorization': `Bearer ${env.key}`, 'apikey': env.key, 'Content-Type': 'application/json' },
                        body: JSON.stringify({ prefix: 'orders/', limit: 1000 })
                    });
                    
                    if (listResp.ok) {
                        const files = await listResp.json();
                        for (const file of files || []) {
                            if (file.name?.endsWith('.json')) {
                                try {
                                    const fileName = file.name.replace('orders/', '');
                                    const orderEndpoint = `${env.url}/storage/v1/object/public/${encodeURIComponent(env.bucket)}/orders/${fileName}`;
                                    const orderResp = await fetch(orderEndpoint, {
                                        headers: { 'Authorization': `Bearer ${env.key}`, 'apikey': env.key }
                                    });
                                    if (orderResp.ok) {
                                        const existingOrder = await orderResp.json();
                                        if (existingOrder.orderNumber == orderNumber) {
                                            existingOrderId = fileName.replace('.json', '');
                                            orderId = existingOrderId;
                                            console.log(`‚úÖ ◊†◊û◊¶◊ê◊î ◊î◊ñ◊û◊†◊î ◊ß◊ô◊ô◊û◊™ ◊¢◊ù ◊ê◊ï◊™◊ï ◊û◊°◊§◊®: ${orderNumber}, ◊û◊¢◊ì◊õ◊ü ◊ê◊ï◊™◊î`);
                                            break;
                                        }
                                    }
                                } catch (e) {
                                    console.warn('Error checking file:', e);
                                }
                            }
                        }
                    }
                }
            } catch (e) {
                console.warn('Failed to check for existing order:', e);
            }
        }
        
        const finalOrderNumber = orderNumber || (Math.floor(Math.random() * 9000) + 1000);
        const now = new Date();
        const orderData = {
            id: orderId,
            orderNumber: finalOrderNumber,
            customerName: customerName || '◊î◊ñ◊û◊†◊î ◊ú◊ú◊ê ◊©◊ù',
            items: items || {},
            total: total || 0,
            notes: notes || '',
            status: 'completed',
            createdAt: existingOrderId ? undefined : now.toISOString(), // ◊®◊ß ◊ê◊ù ◊ó◊ì◊©
            orderDate: orderDate || now.toLocaleDateString('he-IL'),
            orderTime: orderTime || now.toLocaleTimeString('he-IL'),
            createdDate: now.toLocaleDateString('he-IL'),
            createdTime: now.toLocaleTimeString('he-IL'),
            updatedAt: now.toISOString()
        };
        
        // ◊ê◊ù ◊¢◊ì◊õ◊ü ◊î◊ñ◊û◊†◊î ◊ß◊ô◊ô◊û◊™, ◊ú◊ê ◊†◊û◊ó◊ß ◊ê◊™ createdAt
        if (existingOrderId && orderData.createdAt === undefined) {
            delete orderData.createdAt;
        }
        
        // Save locally
        const raw = await fs.readFile(ORDERS_FILE, 'utf8').catch(() => '{"orders":{},"currentOrder":null}');
        const data = JSON.parse(raw || '{}');
        data.orders[orderId] = orderData;
        data.currentOrder = orderId;
        await fs.writeFile(ORDERS_FILE, JSON.stringify(data, null, 2), 'utf8');
        
        // Save to cloud
        try {
            await saveOrderToCloud(orderData);
        } catch (e) {
            console.warn('Cloud save failed:', e?.message || e);
        }
        
        res.json({ success: true, orderId, order: orderData, updated: !!existingOrderId });
    } catch (error) {
        console.error('Error creating order:', error);
        res.status(500).json({ error: '◊©◊í◊ô◊ê◊î ◊ë◊ô◊¶◊ô◊®◊™ ◊î◊î◊ñ◊û◊†◊î' });
    }
});

// Update current order
app.post('/api/orders/update', async (req, res) => {
    try {
        await ensureOrdersData();
        const { items, total, notes, customerName } = req.body;
        
        const raw = await fs.readFile(ORDERS_FILE, 'utf8').catch(() => '{"orders":{},"currentOrder":null}');
        const data = JSON.parse(raw || '{}');
        
        if (!data.currentOrder || !data.orders[data.currentOrder]) {
            return res.status(404).json({ error: '◊ê◊ô◊ü ◊î◊ñ◊û◊†◊î ◊§◊¢◊ô◊ú◊î' });
        }
        
        const order = data.orders[data.currentOrder];
        order.items = items || order.items;
        order.total = total !== undefined ? total : order.total;
        order.notes = notes !== undefined ? notes : order.notes;
        order.customerName = customerName || order.customerName;
        order.updatedAt = new Date().toISOString();
        
        await fs.writeFile(ORDERS_FILE, JSON.stringify(data, null, 2), 'utf8');
        
        // Update in cloud
        try {
            await saveOrderToCloud(order);
        } catch (e) {
            console.warn('Cloud update failed:', e?.message || e);
        }
        
        res.json({ success: true, order });
    } catch (error) {
        console.error('Error updating order:', error);
        res.status(500).json({ error: '◊©◊í◊ô◊ê◊î ◊ë◊¢◊ì◊õ◊ï◊ü ◊î◊î◊ñ◊û◊†◊î' });
    }
});

// Complete current order
app.post('/api/orders/complete', async (req, res) => {
    try {
        await ensureOrdersData();
        const raw = await fs.readFile(ORDERS_FILE, 'utf8').catch(() => '{"orders":{},"currentOrder":null}');
        const data = JSON.parse(raw || '{}');
        
        if (!data.currentOrder || !data.orders[data.currentOrder]) {
            return res.status(404).json({ error: '◊ê◊ô◊ü ◊î◊ñ◊û◊†◊î ◊§◊¢◊ô◊ú◊î' });
        }
        
        const order = data.orders[data.currentOrder];
        order.status = 'completed';
        order.completedAt = new Date().toISOString();
        order.updatedAt = new Date().toISOString();
        
        // Save final version to cloud
        try {
            await saveOrderToCloud(order);
        } catch (e) {
            console.warn('Cloud save failed:', e?.message || e);
        }
        
        // Clear current order
        data.currentOrder = null;
        await fs.writeFile(ORDERS_FILE, JSON.stringify(data, null, 2), 'utf8');
        
        res.json({ success: true, order });
    } catch (error) {
        console.error('Error completing order:', error);
        res.status(500).json({ error: '◊©◊í◊ô◊ê◊î ◊ë◊î◊©◊ú◊û◊™ ◊î◊î◊ñ◊û◊†◊î' });
    }
});

// Get current order
app.get('/api/orders/current', async (req, res) => {
    try {
        await ensureOrdersData();
        const raw = await fs.readFile(ORDERS_FILE, 'utf8').catch(() => '{"orders":{},"currentOrder":null}');
        const data = JSON.parse(raw || '{}');
        
        if (!data.currentOrder || !data.orders[data.currentOrder]) {
            return res.json({ success: true, order: null });
        }
        
        res.json({ success: true, order: data.orders[data.currentOrder] });
    } catch (error) {
        console.error('Error getting current order:', error);
        res.status(500).json({ error: '◊©◊í◊ô◊ê◊î ◊ë◊ß◊ë◊ú◊™ ◊î◊î◊ñ◊û◊†◊î ◊î◊§◊¢◊ô◊ú◊î' });
    }
});

// Get orders history
app.get('/api/orders/history', async (req, res) => {
    try {
        await ensureOrdersData();
        
        // Get local orders
        const raw = await fs.readFile(ORDERS_FILE, 'utf8').catch(() => '{"orders":{},"currentOrder":null}');
        const data = JSON.parse(raw || '{}');
        const localOrders = Object.values(data.orders);
        
        // Get cloud orders
        let cloudOrders = [];
        try {
            const cloudData = await getOrdersFromCloud();
            cloudOrders = cloudData.orders || [];
        } catch (e) {
            console.warn('Failed to get cloud orders:', e?.message || e);
        }
        
        // Combine and deduplicate
        const allOrders = [...localOrders, ...cloudOrders];
        const uniqueOrders = allOrders.reduce((acc, order) => {
            if (!acc.find(o => o.id === order.id)) {
                acc.push(order);
            }
            return acc;
        }, []);
        
        // Sort by date
        uniqueOrders.sort((a, b) => new Date(b.date || b.createdAt) - new Date(a.date || a.createdAt));
        
        res.json({ success: true, orders: uniqueOrders });
    } catch (error) {
        console.error('Error getting orders history:', error);
        res.status(500).json({ error: '◊©◊í◊ô◊ê◊î ◊ë◊ß◊ë◊ú◊™ ◊î◊ô◊°◊ò◊ï◊®◊ô◊ô◊™ ◊î◊î◊ñ◊û◊†◊ï◊™' });
    }
});

// Get all orders (for compatibility with frontend)
app.get('/api/orders', async (req, res) => {
    try {
        await ensureOrdersData();
        
        // Get local orders
        const raw = await fs.readFile(ORDERS_FILE, 'utf8').catch(() => '{"orders":{},"currentOrder":null}');
        const data = JSON.parse(raw || '{}');
        const localOrders = Object.values(data.orders || {});
        
        // If no local orders, try to load from cloud
        if (localOrders.length === 0) {
            console.log('üîÑ No local orders found, attempting to load from cloud...');
            try {
                const cloudData = await getOrdersFromCloud();
                const cloudOrders = cloudData.orders || [];
                if (cloudOrders.length > 0) {
                    console.log(`‚úÖ Loaded ${cloudOrders.length} orders from cloud`);
                    return res.json({ success: true, orders: cloudOrders, count: cloudOrders.length, source: 'cloud' });
                }
            } catch (e) {
                console.warn('Failed to load orders from cloud:', e?.message || e);
            }
        }
        
        // Get cloud orders for additional data
        let cloudOrders = [];
        try {
            const cloudData = await getOrdersFromCloud();
            cloudOrders = cloudData.orders || [];
        } catch (e) {
            console.log('Could not fetch cloud orders:', e.message);
        }
        
        // Combine and deduplicate orders
        const allOrders = [...localOrders, ...cloudOrders];
        const uniqueOrders = allOrders.reduce((acc, order) => {
            const existing = acc.find(o => o.id === order.id);
            if (!existing) {
                acc.push(order);
            } else {
                // Keep the more recent one
                if (new Date(order.updatedAt || order.createdAt) > new Date(existing.updatedAt || existing.createdAt)) {
                    const index = acc.indexOf(existing);
                    acc[index] = order;
                }
            }
            return acc;
        }, []);
        
        // Sort by date
        uniqueOrders.sort((a, b) => new Date(b.date || b.createdAt) - new Date(a.date || a.createdAt));
        
        res.json({ success: true, orders: uniqueOrders });
    } catch (error) {
        console.error('Error getting orders:', error);
        res.status(500).json({ error: '◊©◊í◊ô◊ê◊î ◊ë◊ß◊ë◊ú◊™ ◊î◊î◊ñ◊û◊†◊ï◊™' });
    }
});

// Restore order (load into current order)
app.post('/api/orders/restore', async (req, res) => {
    try {
        await ensureOrdersData();
        const { orderId } = req.body;
        
        if (!orderId) {
            return res.status(400).json({ error: '◊û◊ñ◊î◊î ◊î◊ñ◊û◊†◊î ◊ó◊°◊®' });
        }
        
        let orderData;
        
        // Try to get from local first
        const raw = await fs.readFile(ORDERS_FILE, 'utf8').catch(() => '{"orders":{},"currentOrder":null}');
        const data = JSON.parse(raw || '{}');
        
        if (data.orders[orderId]) {
            orderData = data.orders[orderId];
        } else {
            // Try to get from cloud
            try {
                orderData = await downloadOrderFromCloud(orderId);
            } catch (e) {
                return res.status(404).json({ error: '◊î◊ñ◊û◊†◊î ◊ú◊ê ◊†◊û◊¶◊ê◊î' });
            }
        }
        
        // Create new order based on restored data
        const newOrderId = `order-${Date.now()}`;
        const newOrder = {
            ...orderData,
            id: newOrderId,
            status: 'active',
            createdAt: new Date().toISOString(),
            updatedAt: new Date().toISOString(),
            restoredFrom: orderId
        };
        
        // Save as current order
        data.orders[newOrderId] = newOrder;
        data.currentOrder = newOrderId;
        await fs.writeFile(ORDERS_FILE, JSON.stringify(data, null, 2), 'utf8');
        
        res.json({ success: true, order: newOrder });
    } catch (error) {
        console.error('Error restoring order:', error);
        res.status(500).json({ error: '◊©◊í◊ô◊ê◊î ◊ë◊©◊ó◊ñ◊ï◊® ◊î◊î◊ñ◊û◊†◊î' });
    }
});

// Clear current order
app.post('/api/orders/clear', async (req, res) => {
    try {
        await ensureOrdersData();
        const raw = await fs.readFile(ORDERS_FILE, 'utf8').catch(() => '{"orders":{},"currentOrder":null}');
        const data = JSON.parse(raw || '{}');
        
        data.currentOrder = null;
        await fs.writeFile(ORDERS_FILE, JSON.stringify(data, null, 2), 'utf8');
        
        res.json({ success: true, message: '◊î◊î◊ñ◊û◊†◊î ◊î◊§◊¢◊ô◊ú◊î ◊†◊ï◊ß◊™◊î' });
    } catch (error) {
        console.error('Error clearing order:', error);
        res.status(500).json({ error: '◊©◊í◊ô◊ê◊î ◊ë◊†◊ô◊ß◊ï◊ô ◊î◊î◊ñ◊û◊†◊î' });
    }
});

// WhatsApp message sending endpoint
app.post('/send-whatsapp', async (req, res) => {
    console.log('Received WhatsApp request:', req.body);
    
    try {
        // ◊ë◊ì◊ô◊ß◊™ ◊î◊û◊ô◊ô◊ú ◊î◊û◊ï◊®◊©◊î
        const userEmail = req.body.userEmail;
        if (!userEmail) {
            return res.status(401).json({ 
                error: '◊ê◊ô◊ü ◊û◊ô◊ô◊ú ◊û◊©◊™◊û◊© ◊ë◊ë◊ß◊©◊î',
                details: '◊†◊ì◊®◊©◊™ ◊î◊™◊ó◊ë◊®◊ï◊™ ◊¢◊ù Google' 
            });
        }
        
        if (!isEmailAuthorized(userEmail)) {
            return res.status(403).json({ 
                error: '◊û◊ô◊ô◊ú ◊ú◊ê ◊û◊ï◊®◊©◊î',
                details: `◊î◊û◊ô◊ô◊ú ${userEmail} ◊ê◊ô◊†◊ï ◊û◊ï◊®◊©◊î ◊ú◊©◊ú◊ï◊ó ◊î◊ï◊ì◊¢◊ï◊™ WhatsApp` 
            });
        }
        
        // ◊ß◊ë◊ú◊™ ◊û◊ñ◊î◊î ◊î◊ß◊ë◊ï◊¶◊î ◊û◊î◊ë◊ß◊©◊î
        const groupId = req.body.groupId || GROUPS.CONDITORIA; // ◊ë◊®◊ô◊®◊™ ◊û◊ó◊ì◊ú ◊ú◊ß◊ë◊ï◊¶◊™ ◊î◊ß◊ï◊†◊ì◊ô◊ò◊ï◊®◊ô◊î
        
        const requestBody = {
            chatId: groupId,
            message: req.body.message
        };
        
        console.log('Sending to Green API:', requestBody);
        console.log('Authorized user:', userEmail);
        
        const response = await fetch(`${BASE_URL}/sendMessage/${API_TOKEN}`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify(requestBody)
        });
        
        const data = await response.json();
        console.log('Green API response:', data);
        
        if (!response.ok) {
            console.error('Green API error:', data);
            throw new Error(data.message || '◊©◊í◊ô◊ê◊î ◊ë◊©◊ú◊ô◊ó◊™ ◊î◊î◊ï◊ì◊¢◊î');
        }
        
        res.json(data);
    } catch (error) {
        console.error('Server error:', error);
        res.status(500).json({ 
            error: 'Failed to send message',
            details: error.message 
        });
    }
});

// Port configuration
const PORT = process.env.PORT || 5000;

// Initialize data locations, categories/products and start server
async function bootAutoRestoreIfNeeded() {
    try {
        await ensureDataLocations();
        const autoRestore = process.env.AUTO_RESTORE_ON_EMPTY === 'true';
        if (!autoRestore) {
            console.log('Boot auto-restore disabled (AUTO_RESTORE_ON_EMPTY!=true)');
            return;
        }
        const raw = await fs.readFile(DATA_PRODUCTS_FILE, 'utf8').catch(() => null);
        const data = raw ? JSON.parse(raw || '{}') : { products: {} };
        const count = data.products ? Object.keys(data.products).length : 0;
        if (count > 0) {
            console.log('Boot auto-restore skipped: products exist:', count);
            return;
        }
        console.log('üü° Boot auto-restore: products are empty, searching latest backup across all sources...');
        const desc = await findLatestBackupAcrossSources();
        if (!desc) {
            console.log('Boot auto-restore: no backups found');
            return;
        }
        const ok = await restoreFromDescriptor(desc);
        console.log('Boot auto-restore result:', ok ? `restored from ${desc.source}` : 'failed');
    } catch (e) {
        console.warn('Boot auto-restore error:', e?.message || e);
    }
}

ensureDataLocations().then(() => initializeCategories()).then(() => importProductsIfEmpty()).then(() => ensureOrdersData()).then(() => bootAutoRestoreIfNeeded()).then(() => {
    app.listen(PORT, () => {
        console.log(`Server is running on port ${PORT}`);
        console.log('Server is ready to handle requests');
    });
    // Start scheduled conditional backups only if explicitly enabled
    if (process.env.BACKUP_ENABLED === 'true') {
        scheduleDailyConditionalBackup();
    } else {
        console.log('Scheduled backups are disabled (BACKUP_ENABLED!=true)');
    }
}).catch(error => {
    console.error('Failed to start server:', error);
    process.exit(1);
});

